{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "# plt.rcParams['image.cmap'] = 'gray'\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "import keras_core as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Input((3,)),\n",
    "    keras.layers.Dense(10, activation=\"relu\"),\n",
    "    keras.layers.Dense(3, activation=\"relu\"),\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x_train = np.random.rand(64, 3)\n",
    "y_train = np.zeros((64, 3))\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(\n",
    "    torch.from_numpy(x_train), torch.from_numpy(y_train)\n",
    ")\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=16, shuffle=True\n",
    ")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=1e-2)\n",
    "\n",
    "def my_loss(target, output):\n",
    "    return keras.ops.abs(42 - keras.ops.mean(output))\n",
    "\n",
    "loss_fn = my_loss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "model.layers[1].trainable = False\n",
    "model.compile()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 41.8906\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 41.8863\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 41.8412\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 41.8639\n",
      "epoch 1\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 41.8165\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 41.7796\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 41.7865\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 41.8073\n",
      "epoch 2\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 41.7425\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 41.7190\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 41.7050\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 41.6457\n",
      "epoch 3\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 41.6341\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 41.5733\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 41.5848\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 41.5884\n",
      "epoch 4\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 41.5179\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 41.4685\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 41.4389\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 41.4827\n",
      "epoch 5\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 41.4438\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 41.3387\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 41.3609\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 41.2932\n",
      "epoch 6\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 41.2529\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 41.2176\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 41.2745\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 41.2276\n",
      "epoch 7\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 41.1418\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 41.2359\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 41.0667\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 41.0633\n",
      "epoch 8\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 41.0577\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 41.0337\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 40.9702\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 40.9881\n",
      "epoch 9\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 40.9491\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 40.7456\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 40.9445\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 40.9590\n",
      "epoch 10\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 40.8035\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 40.7908\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 40.7246\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 40.8230\n",
      "epoch 11\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 40.6257\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 40.6226\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 40.6994\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 40.7479\n",
      "epoch 12\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 40.6476\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 40.7663\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 40.4294\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 40.3926\n",
      "epoch 13\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 40.4527\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 40.4624\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 40.4835\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 40.3978\n",
      "epoch 14\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 40.3860\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 40.4069\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 40.3895\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 40.1642\n",
      "epoch 15\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 40.2802\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 40.2190\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 40.1739\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 40.2349\n",
      "epoch 16\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 40.0667\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 40.1744\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 40.1372\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 40.0877\n",
      "epoch 17\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 40.0135\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 39.9366\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 40.0797\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 39.9946\n",
      "epoch 18\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 39.7664\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 39.7145\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 39.9490\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 40.1595\n",
      "epoch 19\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 40.0246\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 39.7103\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 39.7848\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 39.6176\n",
      "epoch 20\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 39.6534\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 39.5238\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 39.8625\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 39.6677\n",
      "epoch 21\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 39.6530\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 39.6544\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 39.5617\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 39.3960\n",
      "epoch 22\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 39.4955\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 39.6544\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 39.4886\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 39.1892\n",
      "epoch 23\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 39.2888\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 39.3618\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 39.5679\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 39.1775\n",
      "epoch 24\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 39.3724\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 39.1724\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 39.2036\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 39.2119\n",
      "epoch 25\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 39.1818\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 39.2042\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 39.0867\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 39.0534\n",
      "epoch 26\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 39.2909\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 38.8474\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 38.8600\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 39.0927\n",
      "epoch 27\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 39.0760\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 38.8138\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 38.8035\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 38.9636\n",
      "epoch 28\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 38.8478\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 38.8405\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 38.7194\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 38.8158\n",
      "epoch 29\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 38.7728\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 38.8673\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 38.6883\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 38.4598\n",
      "epoch 30\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 38.5329\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 38.5250\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 38.5092\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 38.7952\n",
      "epoch 31\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 38.5367\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 38.4817\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 38.5563\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 38.3495\n",
      "epoch 32\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 38.4556\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 38.2429\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 38.3135\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 38.4838\n",
      "epoch 33\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 38.2496\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 38.2918\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 38.1519\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 38.3688\n",
      "epoch 34\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 38.3262\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 37.7725\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 38.5648\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 37.9665\n",
      "epoch 35\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 38.1876\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 38.0523\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 38.1065\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 37.8506\n",
      "epoch 36\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 37.9797\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 37.6860\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 37.9858\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 38.1203\n",
      "epoch 37\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 37.6007\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 38.2929\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 37.8405\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 37.6027\n",
      "epoch 38\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 37.9401\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 37.5634\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 37.6742\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 37.7282\n",
      "epoch 39\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 37.5896\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 37.5986\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 37.8339\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 37.4549\n",
      "epoch 40\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 37.7850\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 37.5609\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 37.2932\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 37.4059\n",
      "epoch 41\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 37.8752\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 37.2683\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 37.1359\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 37.3355\n",
      "epoch 42\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 37.1724\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 37.7188\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 37.3382\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 36.9583\n",
      "epoch 43\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 36.9723\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 37.7752\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 36.7567\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 37.2566\n",
      "epoch 44\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 37.0688\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 36.9747\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 37.0816\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 37.2063\n",
      "epoch 45\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 37.6304\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 36.7192\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 36.6479\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 36.8980\n",
      "epoch 46\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 36.6237\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 36.8391\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 36.8742\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 37.1392\n",
      "epoch 47\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 36.5084\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 36.6626\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 37.0801\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 36.7939\n",
      "epoch 48\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 37.0611\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 36.7105\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 36.4953\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 36.3420\n",
      "epoch 49\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 37.0220\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 36.3982\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 36.2258\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 36.5374\n",
      "epoch 50\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 36.3239\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 36.5883\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 36.4116\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 36.4354\n",
      "epoch 51\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 36.1554\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 36.3974\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 36.5071\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 36.2705\n",
      "epoch 52\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 36.8696\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 36.2166\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 35.9975\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 35.8116\n",
      "epoch 53\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 36.4207\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 36.0795\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 36.2296\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 35.7413\n",
      "epoch 54\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 36.2582\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 35.7846\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 36.0931\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 35.9103\n",
      "epoch 55\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 35.9506\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 36.0079\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 35.6776\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 35.9826\n",
      "epoch 56\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 36.0824\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 36.4144\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 35.3155\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 35.3724\n",
      "epoch 57\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 36.2510\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 35.8468\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 35.5557\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 35.1044\n",
      "epoch 58\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 35.8063\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 35.9015\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 35.2030\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 35.4245\n",
      "epoch 59\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 35.3898\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 35.4237\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 36.0756\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 35.0202\n",
      "epoch 60\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 35.2247\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 35.3938\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 35.4633\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 35.4007\n",
      "epoch 61\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 35.2757\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 35.7517\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 35.2004\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 34.8226\n",
      "epoch 62\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 34.5790\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 34.9008\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 35.4934\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 35.6598\n",
      "epoch 63\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 35.3179\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 34.7269\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 35.0393\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 35.1130\n",
      "epoch 64\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 35.5062\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 34.5457\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 34.6840\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 35.0331\n",
      "epoch 65\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 34.5370\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 35.7071\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 34.6953\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 34.4027\n",
      "epoch 66\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 35.0154\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 34.5887\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 34.2378\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 35.0764\n",
      "epoch 67\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 34.4377\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 34.6511\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 34.7506\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 34.6531\n",
      "epoch 68\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 34.4392\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 35.1845\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 33.9266\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 34.5124\n",
      "epoch 69\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 34.2864\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 34.7761\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 34.0623\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 34.5133\n",
      "epoch 70\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 34.7595\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 34.0274\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 34.0622\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 34.3607\n",
      "epoch 71\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 34.0700\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 33.8287\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 34.4752\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 34.4133\n",
      "epoch 72\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 34.1998\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 34.2041\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 34.0692\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 33.8835\n",
      "epoch 73\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 33.7780\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 34.1423\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 33.7072\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 34.3060\n",
      "epoch 74\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 32.9959\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 34.2335\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 34.0074\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 34.2731\n",
      "epoch 75\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 33.8352\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 33.4859\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 34.3173\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 33.4391\n",
      "epoch 76\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 33.4896\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 34.4218\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 33.0746\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 33.6655\n",
      "epoch 77\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 34.0304\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 33.1135\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 33.0413\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 34.0424\n",
      "epoch 78\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 33.5533\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 33.4192\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 33.0785\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 33.7504\n",
      "epoch 79\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 34.3101\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 33.3713\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 32.8594\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 32.8283\n",
      "epoch 80\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 33.0297\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 32.9500\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 33.7356\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 33.2376\n",
      "epoch 81\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 33.4313\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 33.7661\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 32.6816\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 32.6413\n",
      "epoch 82\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 33.7919\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 33.0719\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 32.7565\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 32.4744\n",
      "epoch 83\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 33.3969\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 32.9724\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 32.7491\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 32.5531\n",
      "epoch 84\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 32.2307\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 33.0650\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 33.6906\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 32.2634\n",
      "epoch 85\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 33.9232\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 31.6575\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 32.8190\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 32.4191\n",
      "epoch 86\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 32.1605\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 33.0767\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 32.3458\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 32.8154\n",
      "epoch 87\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 32.5315\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 31.7818\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 32.6267\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 33.0332\n",
      "epoch 88\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 31.9593\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 32.1746\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 32.6781\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 32.7348\n",
      "epoch 89\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 31.3397\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 32.4065\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 32.3251\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 33.0519\n",
      "epoch 90\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 32.7699\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 32.1614\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 31.7273\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 32.0290\n",
      "epoch 91\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 31.8438\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 32.8124\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 31.6951\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 31.9144\n",
      "epoch 92\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 32.6065\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 31.2396\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 32.0154\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 31.9800\n",
      "epoch 93\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 32.2800\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 32.6235\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 32.1241\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 30.3834\n",
      "epoch 94\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 31.7970\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 31.6408\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 31.5802\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 31.9768\n",
      "epoch 95\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 30.7818\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 32.3422\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 31.9335\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 31.5124\n",
      "epoch 96\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 31.2315\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 31.3618\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 30.9915\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 32.5610\n",
      "epoch 97\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 31.7145\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 30.9383\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 31.0015\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 32.0627\n",
      "epoch 98\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 30.2056\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 31.4885\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 32.3229\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 31.2773\n",
      "epoch 99\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 0: 31.2341\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 1: 32.0706\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 2: 30.6815\n",
      "the frozen weights did not change\n",
      "Training loss (for 1 batch) at step 3: 30.8757\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    print(\"epoch\", epoch)\n",
    "    for step, (inputs, targets) in enumerate(train_dataloader):\n",
    "        # for frozen_layer_ix in range(2):\n",
    "        # Forward pass\n",
    "        weights_before = model.layers[1].get_weights()\n",
    "        output = model(inputs)\n",
    "        loss = loss_fn(targets, output)\n",
    "\n",
    "        # Backward pass\n",
    "        model.zero_grad()\n",
    "        trainable_weights = [v for v in model.trainable_weights]\n",
    "\n",
    "        # Call torch.Tensor.backward() on the loss to compute gradients\n",
    "        # for the weights.\n",
    "        loss.backward()\n",
    "        gradients = [v.value.grad for v in trainable_weights]\n",
    "\n",
    "        # Update weights\n",
    "        with torch.no_grad():\n",
    "            optimizer.apply(gradients, trainable_weights)\n",
    "\n",
    "        if False not in [(weights_before[i] == model.layers[1].get_weights()[i]).all() for i in range(len(weights_before))]:\n",
    "            print('the frozen weights did not change')\n",
    "        else:\n",
    "            raise Exception(\"the weights of the frozen layer changed\")\n",
    "\n",
    "        print(\n",
    "            f\"Training loss (for 1 batch) at step {step}: {loss.detach().numpy():.4f}\"\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
